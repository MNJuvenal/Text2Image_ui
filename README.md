# Text2Image Generator

Application complÃ¨te de gÃ©nÃ©ration d'images IA Ã  partir de texte avec traitement local.

## ğŸš€ FonctionnalitÃ©s

- **Interface web intuitive** pour saisir des descriptions textuelles
- **GÃ©nÃ©ration d'images IA** en temps rÃ©el avec Stable Diffusion Turbo
- **Traitement local** avec diffusers et PyTorch
- **TÃ©lÃ©chargement des images** gÃ©nÃ©rÃ©es
- **API backend robuste** avec gestion d'Ã©tat des tÃ¢ches
- **Design responsive** et moderne

## ğŸ“ Structure du projet

```
text2image/
â”œâ”€â”€ frontend/          # Interface React.js
â”œâ”€â”€ backend/           # API Node.js/Express + script Python
â”œâ”€â”€ README.md
â””â”€â”€ package.json
```

## ğŸ› ï¸ PrÃ©requis

- **Node.js** (v16+)
- **Python** (v3.8+)
- **pip** pour les dÃ©pendances Python

## ğŸ”§ Installation

### 1. Cloner le projet
```bash
git clone <repo-url>
cd text2image
```

### 2. Installer les dÃ©pendances Node.js
```bash
# Installation globale
npm run install-all

# Ou installation manuelle
npm install
cd frontend && npm install  
cd ../backend && npm install
```

### 3. Installer les dÃ©pendances Python
```bash
cd backend
pip install -r requirements.txt
```

## ğŸš€ Lancement

### Mode dÃ©veloppement (recommandÃ©)
```bash
npm run dev
```

Cela lance simultanÃ©ment :
- Frontend sur `http://localhost:3000`
- Backend sur `http://localhost:5000`

### Lancement sÃ©parÃ©
```bash
# Terminal 1 - Backend
cd backend && npm run dev

# Terminal 2 - Frontend  
cd frontend && npm start
```

## ğŸ¯ Utilisation

1. **Ouvrez** `http://localhost:3000`
2. **Entrez** une description d'image
3. **Ajustez** les paramÃ¨tres (optionnel)
4. **Cliquez** sur "GÃ©nÃ©rer l'image"
5. **Attendez** la gÃ©nÃ©ration (peut prendre quelques minutes)
6. **TÃ©lÃ©chargez** l'image gÃ©nÃ©rÃ©e

## âš™ï¸ Configuration

Modifiez le fichier `backend/.env` :

```env
PORT=5000
DEFAULT_STEPS=4
DEFAULT_GUIDANCE_SCALE=0.0
# PYTHON_PATH=/usr/bin/python3  # Optionnel
```

## ğŸ¨ ModÃ¨le IA utilisÃ©

- **Stable Diffusion Turbo** (`stabilityai/sd-turbo`)
- **OptimisÃ©** pour la gÃ©nÃ©ration rapide (1-4 Ã©tapes)
- **Compatible** GPU et CPU (GPU recommandÃ©)
- **QualitÃ© Ã©levÃ©e** avec temps de gÃ©nÃ©ration rÃ©duit

## ğŸ“ API Endpoints

### Backend (`http://localhost:5000`)

- `POST /api/generate` - GÃ©nÃ©rer une image
- `GET /api/status/:taskId` - VÃ©rifier le statut
- `GET /api/image/:taskId` - RÃ©cupÃ©rer l'image
- `GET /api/download/:taskId` - TÃ©lÃ©charger l'image
- `GET /api/health` - VÃ©rification de santÃ©

### Exemple d'utilisation API

```javascript
const response = await fetch('/api/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    prompt: "un chat mignon qui joue avec une pelote de laine",
    steps: 4,
    guidance_scale: 0.0
  })
});
```

## ğŸ›ï¸ ParamÃ¨tres de gÃ©nÃ©ration

- **Prompt** : Description textuelle de l'image
- **Steps** : Nombre d'Ã©tapes (1-4 pour SD-Turbo)
- **Guidance Scale** : ContrÃ´le de la fidÃ©litÃ© au prompt (0.0 recommandÃ© pour SD-Turbo)

## ğŸ› ï¸ Technologies utilisÃ©es

### Frontend
- React.js 18
- Styled Components
- Axios

### Backend  
- Node.js
- Express.js
- CORS

### IA/ML
- Python 3.8+
- Diffusers (Hugging Face)
- PyTorch
- Stable Diffusion Turbo

## ğŸš¨ DÃ©pannage

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©
```bash
# Changer le port dans backend/.env
PORT=5001
```

### ProblÃ¨me : Erreur Python
1. VÃ©rifiez que Python est installÃ© (`python --version`)
2. Installez les dÃ©pendances (`pip install -r backend/requirements.txt`)
3. VÃ©rifiez les logs du backend

### ProblÃ¨me : GÃ©nÃ©ration lente
1. Installez PyTorch avec support CUDA si vous avez une GPU
2. RÃ©duisez le nombre d'Ã©tapes (steps) Ã  1-2
3. VÃ©rifiez que votre systÃ¨me a assez de RAM

### ProblÃ¨me : Images ne se chargent pas
1. VÃ©rifiez les logs du backend
2. Testez l'endpoint `/api/health`
3. VÃ©rifiez que le dossier `backend/generated_images` existe

## ğŸ”§ Optimisations

### Pour GPU (recommandÃ©)
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Pour CPU uniquement
Le projet fonctionne sur CPU mais sera plus lent.

## ğŸ“„ Licence

MIT License

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur le repository GitHub.## ğŸ›ï¸ ParamÃ¨tres de gÃ©nÃ©ration

- **Prompt** : Description textuelle de l'image
- **Steps** : Nombre d'Ã©tapes (1-4 pour SD-Turbo)
- **Guidance Scale** : ContrÃ´le de la fidÃ©litÃ© au prompt (0.0 recommandÃ© pour SD-Turbo)

## ğŸ› ï¸ Technologies utilisÃ©es

### Frontend
- React.js 18
- Styled Components
- Axios

### Backend  
- Node.js
- Express.js
- CORS
- Axios

### IA/ML
- Diffusers (Hugging Face)
- PyTorch
- Stable Diffusion Turbo

## ğŸš¨ DÃ©pannage

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©
```bash
# Changer le port dans backend/.env
PORT=5001
```

### ProblÃ¨me : Erreur Colab
1. VÃ©rifiez que le notebook Colab est en cours d'exÃ©cution
2. VÃ©rifiez que l'URL ngrok est correcte dans `.env`
3. RedÃ©marrez le backend aprÃ¨s changement de configuration

### ProblÃ¨me : Images ne se chargent pas
1. VÃ©rifiez les logs du backend
2. Testez l'endpoint `/api/health`
3. VÃ©rifiez la connexion rÃ©seau

## ğŸ“„ Licence

MIT License

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur le repository GitHub.